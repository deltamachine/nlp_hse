{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from lxml import html\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter,defaultdict\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD, NMF, PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "morph = MorphAnalyzer()\n",
    "punct = punctuation+'«»—…“”*№–'\n",
    "stops = set(stopwords.words('russian'))\n",
    "\n",
    "\n",
    "def normalize(text):  \n",
    "    words = [word.strip(punct) for word in text.lower().split()]\n",
    "    words = [morph.parse(word)[0].normal_form for word in words if word and word not in stops]\n",
    "\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "def tokenize(text):  \n",
    "    words = [word.strip(punct) for word in text.lower().split()]\n",
    "\n",
    "    return ' '.join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_xml = html.fromstring(open('paraphrases.xml', 'rb').read())\n",
    "texts_1 = []\n",
    "texts_2 = []\n",
    "classes = []\n",
    "\n",
    "for p in corpus_xml.xpath('//paraphrase'):\n",
    "    texts_1.append(p.xpath('./value[@name=\"text_1\"]/text()')[0])\n",
    "    texts_2.append(p.xpath('./value[@name=\"text_2\"]/text()')[0])\n",
    "    classes.append(p.xpath('./value[@name=\"class\"]/text()')[0])\n",
    "    \n",
    "data = pd.DataFrame({'text_1': texts_1, 'text_2': texts_2, 'label': classes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['text_1_norm'] = data['text_1'].apply(normalize)\n",
    "data['text_2_norm'] = data['text_2'].apply(normalize)\n",
    "data['text_1_notnorm'] = data['text_1'].apply(tokenize)\n",
    "data['text_2_notnorm'] = data['text_2'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>text_1_norm</th>\n",
       "      <th>text_2_norm</th>\n",
       "      <th>text_1_notnorm</th>\n",
       "      <th>text_2_notnorm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Полицейским разрешат стрелять на поражение по ...</td>\n",
       "      <td>Полиции могут разрешить стрелять по хулиганам ...</td>\n",
       "      <td>полицейский разрешить стрелять поражение гражд...</td>\n",
       "      <td>полиция мочь разрешить стрелять хулиган травма...</td>\n",
       "      <td>полицейским разрешат стрелять на поражение по ...</td>\n",
       "      <td>полиции могут разрешить стрелять по хулиганам ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Право полицейских на проникновение в жилище ре...</td>\n",
       "      <td>Правила внесудебного проникновения полицейских...</td>\n",
       "      <td>право полицейский проникновение жилища решить ...</td>\n",
       "      <td>правило внесудебный проникновение полицейский ...</td>\n",
       "      <td>право полицейских на проникновение в жилище ре...</td>\n",
       "      <td>правила внесудебного проникновения полицейских...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Президент Египта ввел чрезвычайное положение в...</td>\n",
       "      <td>Власти Египта угрожают ввести в стране чрезвыч...</td>\n",
       "      <td>президент египет ввести чрезвычайный положение...</td>\n",
       "      <td>власть египет угрожать ввести страна чрезвычай...</td>\n",
       "      <td>президент египта ввел чрезвычайное положение в...</td>\n",
       "      <td>власти египта угрожают ввести в стране чрезвыч...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>Вернувшихся из Сирии россиян волнует вопрос тр...</td>\n",
       "      <td>Самолеты МЧС вывезут россиян из разрушенной Си...</td>\n",
       "      <td>вернуться сирия россиянин волновать вопрос тру...</td>\n",
       "      <td>самолёт мчс вывезти россиянин разрушить сирия</td>\n",
       "      <td>вернувшихся из сирии россиян волнует вопрос тр...</td>\n",
       "      <td>самолеты мчс вывезут россиян из разрушенной сирии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>В Москву из Сирии вернулись 2 самолета МЧС с р...</td>\n",
       "      <td>Самолеты МЧС вывезут россиян из разрушенной Си...</td>\n",
       "      <td>москва сирия вернуться 2 самолёт мчс россиянин...</td>\n",
       "      <td>самолёт мчс вывезти россиянин разрушить сирия</td>\n",
       "      <td>в москву из сирии вернулись 2 самолета мчс с р...</td>\n",
       "      <td>самолеты мчс вывезут россиян из разрушенной сирии</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             text_1  \\\n",
       "0     0  Полицейским разрешат стрелять на поражение по ...   \n",
       "1     0  Право полицейских на проникновение в жилище ре...   \n",
       "2     0  Президент Египта ввел чрезвычайное положение в...   \n",
       "3    -1  Вернувшихся из Сирии россиян волнует вопрос тр...   \n",
       "4     0  В Москву из Сирии вернулись 2 самолета МЧС с р...   \n",
       "\n",
       "                                              text_2  \\\n",
       "0  Полиции могут разрешить стрелять по хулиганам ...   \n",
       "1  Правила внесудебного проникновения полицейских...   \n",
       "2  Власти Египта угрожают ввести в стране чрезвыч...   \n",
       "3  Самолеты МЧС вывезут россиян из разрушенной Си...   \n",
       "4  Самолеты МЧС вывезут россиян из разрушенной Си...   \n",
       "\n",
       "                                         text_1_norm  \\\n",
       "0  полицейский разрешить стрелять поражение гражд...   \n",
       "1  право полицейский проникновение жилища решить ...   \n",
       "2  президент египет ввести чрезвычайный положение...   \n",
       "3  вернуться сирия россиянин волновать вопрос тру...   \n",
       "4  москва сирия вернуться 2 самолёт мчс россиянин...   \n",
       "\n",
       "                                         text_2_norm  \\\n",
       "0  полиция мочь разрешить стрелять хулиган травма...   \n",
       "1  правило внесудебный проникновение полицейский ...   \n",
       "2  власть египет угрожать ввести страна чрезвычай...   \n",
       "3      самолёт мчс вывезти россиянин разрушить сирия   \n",
       "4      самолёт мчс вывезти россиянин разрушить сирия   \n",
       "\n",
       "                                      text_1_notnorm  \\\n",
       "0  полицейским разрешат стрелять на поражение по ...   \n",
       "1  право полицейских на проникновение в жилище ре...   \n",
       "2  президент египта ввел чрезвычайное положение в...   \n",
       "3  вернувшихся из сирии россиян волнует вопрос тр...   \n",
       "4  в москву из сирии вернулись 2 самолета мчс с р...   \n",
       "\n",
       "                                      text_2_notnorm  \n",
       "0  полиции могут разрешить стрелять по хулиганам ...  \n",
       "1  правила внесудебного проникновения полицейских...  \n",
       "2  власти египта угрожают ввести в стране чрезвыч...  \n",
       "3  самолеты мчс вывезут россиян из разрушенной сирии  \n",
       "4  самолеты мчс вывезут россиян из разрушенной сирии  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7227, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нужные инструменты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_embedding(text, model, dim, mode, tfidf):\n",
    "    text = text.split()\n",
    "\n",
    "    words = Counter(text)\n",
    "    total = len(text)\n",
    "    vectors = np.zeros((len(words), dim))\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        try:\n",
    "            v = model[word]\n",
    "            if mode == 'sum':\n",
    "                vectors[i] = v * (words[word] / total)\n",
    "            else:\n",
    "                vectors[i] = (v * (words[word] / total)) * tfidf[word]\n",
    "        except (KeyError, ValueError):\n",
    "            continue\n",
    "    \n",
    "    if vectors.any():\n",
    "        vector = np.average(vectors, axis=0)\n",
    "    else:\n",
    "        vector = np.zeros((dim))\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_vectors(model, data1, data2, mode):\n",
    "    dim = 50\n",
    "    tfidf = TfidfVectorizer(min_df=3, max_df=0.4, max_features=1000)\n",
    "    \n",
    "    tfidf1 = tfidf.fit(data1).vocabulary_\n",
    "    tfidf2 = tfidf.fit(data2).vocabulary_\n",
    "\n",
    "    vec_1 = np.zeros((len(data1), dim))\n",
    "    vec_2 = np.zeros((len(data2), dim))\n",
    "\n",
    "    for i, text in enumerate(data1.values):\n",
    "        vec_1[i] = get_embedding(text, model, dim, mode, tfidf1)\n",
    "\n",
    "    for i, text in enumerate(data2.values):\n",
    "        vec_2[i] = get_embedding(text, model, dim, mode, tfidf2)\n",
    "        \n",
    "    return vec_1, vec_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(min_df=3, max_df=0.4, max_features=1000)\n",
    "tfidf = TfidfVectorizer(min_df=3, max_df=0.4, max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_rt = pd.read_csv('news_texts.csv')\n",
    "data_rt.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v = gensim.models.Word2Vec([text.split() for text in data_rt['content_norm']], size=50, sg=1)\n",
    "fast_text = gensim.models.FastText([text.split() for text in data_rt['content_norm']], size=50, min_n=4, max_n=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svd_cv_1 = svd.fit_transform(cv.fit_transform(data['text_1_norm']))\n",
    "svd_cv_2 = svd.fit_transform(cv.fit_transform(data['text_2_norm']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svd_tfidf_1 = svd.fit_transform(tfidf.fit_transform(data['text_1_norm']))\n",
    "svd_tfidf_2 = svd.fit_transform(tfidf.fit_transform(data['text_2_norm']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmf = NMF(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmf_cv_1 = nmf.fit_transform(cv.fit_transform(data['text_1_norm']))\n",
    "nmf_cv_2 = nmf.fit_transform(cv.fit_transform(data['text_2_norm']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmf_tfidf_1 = nmf.fit_transform(tfidf.fit_transform(data['text_1_norm']))\n",
    "nmf_tfidf_2 = nmf.fit_transform(tfidf.fit_transform(data['text_2_norm']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deltamachine/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "w2v_1, w2v_2 = create_vectors(w2v, data['text_1_norm'], data['text_2_norm'], 'sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deltamachine/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "w2v_tfidf_1, w2v_tfidf_2 = create_vectors(w2v, data['text_1_norm'], data['text_2_norm'], 'tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deltamachine/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "ft_1, ft_2 = create_vectors(fast_text, data['text_1_norm'], data['text_2_norm'], 'sum')\n",
    "ft_notnorm_1, ft_notnorm_2 = create_vectors(fast_text, data['text_1_notnorm'], data['text_2_notnorm'], 'sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deltamachine/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "ft_tfidf_1, ft_tfidf_2 = create_vectors(fast_text, data['text_1_norm'], data['text_2_norm'], 'tfidf')\n",
    "ft_notnorm_tfidf_1, ft_notnorm_tfidf_2 = create_vectors(fast_text, data['text_1_notnorm'], data['text_2_notnorm'], 'tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучающая выборка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_cosine(array1, array2):\n",
    "    sims = []\n",
    "\n",
    "    for vec1, vec2 in zip(array1, array2):\n",
    "        cos_sim = cosine_distances(vec1.reshape(1, -1), vec2.reshape(1, -1))\n",
    "        sims.append(cos_sim[0][0])\n",
    "    \n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_df(svd_cv_1, svd_cv_2, svd_tfidf_1, svd_tfidf_2, nmf_cv_1, nmf_cv_2,\n",
    "                       nmf_tfidf_1, nmf_tfidf_2, w2v_1, w2v_2, w2v_tfidf_1, w2v_tfidf_2,\n",
    "                       ft_1, ft_2, ft_tfidf_1, ft_tfidf_2, ft_notnorm_1, ft_notnorm_2,\n",
    "                       ft_notnorm_tfidf_1, ft_notnorm_tfidf_2):\n",
    "    \n",
    "    svd_cv_sims = calc_cosine(svd_cv_1, svd_cv_2)\n",
    "    svd_tfidf_sims = calc_cosine(svd_tfidf_1, svd_tfidf_2)\n",
    "    nmf_cv_sims = calc_cosine(nmf_cv_1, nmf_cv_2)\n",
    "    nmf_tfidf_sims = calc_cosine(nmf_tfidf_1, nmf_tfidf_2)\n",
    "    w2v_sims = calc_cosine(w2v_1, w2v_2)\n",
    "    w2v_tfidf_sims = calc_cosine(w2v_tfidf_1, w2v_tfidf_2)\n",
    "    ft_sims = calc_cosine(ft_1, ft_2)\n",
    "    ft_tfidf_sims = calc_cosine(ft_tfidf_1, ft_tfidf_2)\n",
    "    ft_notnorm_sims = calc_cosine(ft_notnorm_1, ft_notnorm_2)\n",
    "    ft_notnorm_tfidf_sims = calc_cosine(ft_notnorm_tfidf_1, ft_notnorm_tfidf_2)\n",
    "    \n",
    "    new_df = pd.DataFrame(data={'svd_cv': svd_cv_sims, 'svd_tfidf': svd_tfidf_sims,\n",
    "                            'nmf_cv': nmf_cv_sims, 'nmf_tfidf': nmf_tfidf_sims,\n",
    "                            'w2v': w2v_sims, 'w2v_tfidf': w2v_tfidf_sims,\n",
    "                            'ft': ft_sims, 'ft_tfidf': ft_tfidf_sims,\n",
    "                            'ft_notnorm': ft_notnorm_sims, 'ft_notnorm_tfidf': ft_notnorm_tfidf_sims})\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ft</th>\n",
       "      <th>ft_notnorm</th>\n",
       "      <th>ft_notnorm_tfidf</th>\n",
       "      <th>ft_tfidf</th>\n",
       "      <th>nmf_cv</th>\n",
       "      <th>nmf_tfidf</th>\n",
       "      <th>svd_cv</th>\n",
       "      <th>svd_tfidf</th>\n",
       "      <th>w2v</th>\n",
       "      <th>w2v_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.244800</td>\n",
       "      <td>0.189682</td>\n",
       "      <td>1.112563e+00</td>\n",
       "      <td>0.236303</td>\n",
       "      <td>0.962197</td>\n",
       "      <td>0.997646</td>\n",
       "      <td>1.023312</td>\n",
       "      <td>1.011008</td>\n",
       "      <td>0.077090</td>\n",
       "      <td>0.047405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.183456</td>\n",
       "      <td>0.221199</td>\n",
       "      <td>1.776357e-15</td>\n",
       "      <td>0.425990</td>\n",
       "      <td>0.859799</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.832068</td>\n",
       "      <td>0.982782</td>\n",
       "      <td>0.090184</td>\n",
       "      <td>0.335754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.156042</td>\n",
       "      <td>0.277384</td>\n",
       "      <td>4.906398e-01</td>\n",
       "      <td>0.582511</td>\n",
       "      <td>0.968937</td>\n",
       "      <td>0.690889</td>\n",
       "      <td>1.140478</td>\n",
       "      <td>1.053396</td>\n",
       "      <td>0.047743</td>\n",
       "      <td>0.285524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.377974</td>\n",
       "      <td>0.290506</td>\n",
       "      <td>1.281028e-02</td>\n",
       "      <td>0.153267</td>\n",
       "      <td>0.998754</td>\n",
       "      <td>0.975273</td>\n",
       "      <td>1.030974</td>\n",
       "      <td>1.017624</td>\n",
       "      <td>0.267040</td>\n",
       "      <td>0.153700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.309268</td>\n",
       "      <td>0.430101</td>\n",
       "      <td>4.417429e-02</td>\n",
       "      <td>0.035608</td>\n",
       "      <td>0.988798</td>\n",
       "      <td>0.998602</td>\n",
       "      <td>0.935794</td>\n",
       "      <td>1.033440</td>\n",
       "      <td>0.077500</td>\n",
       "      <td>0.035003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ft  ft_notnorm  ft_notnorm_tfidf  ft_tfidf    nmf_cv  nmf_tfidf  \\\n",
       "0  0.244800    0.189682      1.112563e+00  0.236303  0.962197   0.997646   \n",
       "1  0.183456    0.221199      1.776357e-15  0.425990  0.859799   0.999966   \n",
       "2  0.156042    0.277384      4.906398e-01  0.582511  0.968937   0.690889   \n",
       "3  0.377974    0.290506      1.281028e-02  0.153267  0.998754   0.975273   \n",
       "4  0.309268    0.430101      4.417429e-02  0.035608  0.988798   0.998602   \n",
       "\n",
       "     svd_cv  svd_tfidf       w2v  w2v_tfidf  \n",
       "0  1.023312   1.011008  0.077090   0.047405  \n",
       "1  0.832068   0.982782  0.090184   0.335754  \n",
       "2  1.140478   1.053396  0.047743   0.285524  \n",
       "3  1.030974   1.017624  0.267040   0.153700  \n",
       "4  0.935794   1.033440  0.077500   0.035003  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = create_new_df(svd_cv_1, svd_cv_2, svd_tfidf_1, svd_tfidf_2, nmf_cv_1, nmf_cv_2,\n",
    "                       nmf_tfidf_1, nmf_tfidf_2, w2v_1, w2v_2, w2v_tfidf_1, w2v_tfidf_2,\n",
    "                       ft_1, ft_2, ft_tfidf_1, ft_tfidf_2, ft_notnorm_1, ft_notnorm_2,\n",
    "                       ft_notnorm_tfidf_1, ft_notnorm_tfidf_2)\n",
    "\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее качество (f1 micro) на 5 фолдах =  0.544869581643414\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lr = LogisticRegression(random_state=55518)\n",
    "mean_cvs = np.mean(cross_val_score(lr, new_df, data['label'], scoring='f1_micro', cv=5))\n",
    "\n",
    "print('Среднее качество (f1 micro) на 5 фолдах = ', mean_cvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбор параметров\n",
    "\n",
    "1) Был показатель 100 для TruncatedSVD, стал 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее качество (f1 micro) на 5 фолдах =  0.5487476033286147\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(50)\n",
    "\n",
    "svd_cv_1 = svd.fit_transform(cv.fit_transform(data['text_1_norm']))\n",
    "svd_cv_2 = svd.fit_transform(cv.fit_transform(data['text_2_norm']))\n",
    "\n",
    "svd_tfidf_1 = svd.fit_transform(tfidf.fit_transform(data['text_1_norm']))\n",
    "svd_tfidf_2 = svd.fit_transform(tfidf.fit_transform(data['text_2_norm']))\n",
    "\n",
    "new_df = create_new_df(svd_cv_1, svd_cv_2, svd_tfidf_1, svd_tfidf_2, nmf_cv_1, nmf_cv_2,\n",
    "                       nmf_tfidf_1, nmf_tfidf_2, w2v_1, w2v_2, w2v_tfidf_1, w2v_tfidf_2,\n",
    "                       ft_1, ft_2, ft_tfidf_1, ft_tfidf_2, ft_notnorm_1, ft_notnorm_2,\n",
    "                       ft_notnorm_tfidf_1, ft_notnorm_tfidf_2)\n",
    "\n",
    "mean_cvs = np.mean(cross_val_score(lr, new_df, data['label'], scoring='f1_micro', cv=5))\n",
    "print('Среднее качество (f1 micro) на 5 фолдах = ', mean_cvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество улучшилось, но незначительно.\n",
    "Изменим параметр NMF c 50 до 150 (оставив новые svd)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее качество (f1 micro) на 5 фолдах =  0.544869583630642\n"
     ]
    }
   ],
   "source": [
    "nmf = NMF(150)\n",
    "\n",
    "nmf_cv_1 = nmf.fit_transform(cv.fit_transform(data['text_1_norm']))\n",
    "nmf_cv_2 = nmf.fit_transform(cv.fit_transform(data['text_2_norm']))\n",
    "\n",
    "nmf_tfidf_1 = nmf.fit_transform(tfidf.fit_transform(data['text_1_norm']))\n",
    "nmf_tfidf_2 = nmf.fit_transform(tfidf.fit_transform(data['text_2_norm']))\n",
    "\n",
    "new_df = create_new_df(svd_cv_1, svd_cv_2, svd_tfidf_1, svd_tfidf_2, nmf_cv_1, nmf_cv_2,\n",
    "                       nmf_tfidf_1, nmf_tfidf_2, w2v_1, w2v_2, w2v_tfidf_1, w2v_tfidf_2,\n",
    "                       ft_1, ft_2, ft_tfidf_1, ft_tfidf_2, ft_notnorm_1, ft_notnorm_2,\n",
    "                       ft_notnorm_tfidf_1, ft_notnorm_tfidf_2)\n",
    "\n",
    "mean_cvs = np.mean(cross_val_score(lr, new_df, data['label'], scoring='f1_micro', cv=5))\n",
    "print('Среднее качество (f1 micro) на 5 фолдах = ', mean_cvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество не улучшилось. Можно изменить параметр C у логрега."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее качество (f1 micro) на 5 фолдах =  0.5307523088458476\n"
     ]
    }
   ],
   "source": [
    "lr_new = LogisticRegression(C=0.1)\n",
    "\n",
    "mean_cvs = np.mean(cross_val_score(lr_new, new_df, data['label'], scoring='f1_micro', cv=5))\n",
    "print('Среднее качество (f1 micro) на 5 фолдах = ', mean_cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее качество (f1 micro) на 5 фолдах =  0.5217585371957033\n"
     ]
    }
   ],
   "source": [
    "lr_new = LogisticRegression(C=0.01)\n",
    "\n",
    "mean_cvs = np.mean(cross_val_score(lr_new, new_df, data['label'], scoring='f1_micro', cv=5))\n",
    "print('Среднее качество (f1 micro) на 5 фолдах = ', mean_cvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уменьшение параметра C снижает качество. Можно попробовать изменить penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее качество (f1 micro) на 5 фолдах =  0.5553875699543143\n"
     ]
    }
   ],
   "source": [
    "lr_new = LogisticRegression(penalty='l1')\n",
    "\n",
    "mean_cvs = np.mean(cross_val_score(lr_new, new_df, data['label'], scoring='f1_micro', cv=5))\n",
    "print('Среднее качество (f1 micro) на 5 фолдах = ', mean_cvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество улучшилось."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
