{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.wsd import lesk\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "punct = punctuation+'«»—…“”*№–'\n",
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    words = [word.strip(punct) for word in text.lower().split() if word and word not in stops]\n",
    "    words = [word for word in words if word]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_words_in_context(words, window=3):\n",
    "    words_in_context = []\n",
    "    l = len(words)\n",
    "    \n",
    "    for i in range(l):\n",
    "        context = [words[i], []]\n",
    "        \n",
    "        if i < window:\n",
    "            context[1] += words[:i]\n",
    "        else:\n",
    "            context[1] += words[i-window:i]\n",
    "            \n",
    "        if l - i < window:\n",
    "            context[1] += words[i+1:]\n",
    "        else:\n",
    "            context[1] += words[i+1:i+1+window]\n",
    "            \n",
    "        words_in_context.append(context)\n",
    "        \n",
    "    \n",
    "    return words_in_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, [1, 2, 3]],\n",
       " [1, [0, 2, 3, 4]],\n",
       " [2, [0, 1, 3, 4, 5]],\n",
       " [3, [0, 1, 2, 4, 5, 6]],\n",
       " [4, [1, 2, 3, 5, 6, 7]],\n",
       " [5, [2, 3, 4, 6, 7, 8]],\n",
       " [6, [3, 4, 5, 7, 8, 9]],\n",
       " [7, [4, 5, 6, 8, 9]],\n",
       " [8, [5, 6, 7, 9]],\n",
       " [9, [6, 7, 8]]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_words_in_context(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_lesk(word, sentence):\n",
    "    sent_context = tokenize(sentence)\n",
    "    bestsense = None\n",
    "    maxoverlap = 0\n",
    "    \n",
    "    for synset in wn.synsets(word):\n",
    "        definition = tokenize(synset.definition())\n",
    "        overlap = len(set(sent_context) & set(definition))\n",
    "        \n",
    "        if overlap > maxoverlap:\n",
    "            maxoverlap = overlap\n",
    "            bestsense = synset\n",
    "      \n",
    "    return bestsense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('kind.n.01') a category of things distinguished by some common characteristic or quality\n",
      "Synset('kind.a.01') having or showing a tender and considerate and helpful nature; used especially of persons and their behavior\n",
      "Synset('kind.s.02') agreeable, conducive to comfort\n",
      "Synset('kind.s.03') tolerant and forgiving under provocation\n"
     ]
    }
   ],
   "source": [
    "word = 'kind'\n",
    "\n",
    "for synset in wn.synsets(word):\n",
    "    print(synset, synset.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('kind.a.01')\n"
     ]
    }
   ],
   "source": [
    "print(custom_lesk('kind', 'He is so helpful and kind person!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('kind.n.01')\n"
     ]
    }
   ],
   "source": [
    "print(custom_lesk('kind', 'It is a kind of things we will never understand.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним с Леском из NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('kind.a.01')\n"
     ]
    }
   ],
   "source": [
    "context = ['He', 'is', 'so', 'helpful', 'and', 'kind', 'person', '!', '.']\n",
    "\n",
    "print(lesk(context, 'kind'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('kind.n.01')\n"
     ]
    }
   ],
   "source": [
    "context = ['It', 'is', 'a', 'kind', 'of', 'things', 'we', 'will', 'never', 'understand', '.']\n",
    "\n",
    "print(lesk(context, 'kind'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
